p <- x/sum(x)
clear
clear()
clean()
x <- 1:4
p <- x/sum(x)
temp <- rbind(x,p)
rownames(temp) <- c("X", "Prob")
temp
mean(temp)
sum(temp[1,]*temp[2,])
0.1+0.4+0.9+1.6
install.packages("UsingR")
library(UsingR); data(galton)
install.packages("MASS")
install.packages("MASS")
library(UsingR); data(galton)
library(UsingR); data(galton)
library(UsingR); data(galton)
par(mfrow=c(1,2))
hist(galton$child, col="blue", breaks=100)
hist(galton$parent, col="blue", breaks=100)
plot(galton$parent, galton$child, pch=19)
x <- c(0.18, -1.54, 0.42, 0.95)
w <- c(2,1,3,1)
cor(x,w)
cor(w,x)
cor(w,x)*sd(w)/sd(x)
cor(w,x)*sd(x)/sd(w)
mean(x)
u <- 0.3
sum(w*(x-u)^2)
u <- 1.077
sum(w*(x-u)^2)
u <- 0.0025
sum(w*(x-u)^2)
u <- 0.1471
sum(w*(x-u)^2)
mean(w*x)
mean(w)
mean(x)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
yc <- y - mean(y)
xc <- x - mean(x)
beta1 <- sum(yc*xc)/sum(xc^2)
c(beta1)
data(mtcars)
mpg <- mtcars$mpg
weight <- mtcars$weight
mpgc <- mpg - mean(mpg)
weightc <- weight - mean(weight)
beta <- sum(mpgc*weightc)/sum(weightc^2)
c(beta)
data(mtcars)
mpg <- mtcars$mpg
weight <- mtcars$weight
good <- complete.cases(mpg)
mpg <- mpg[good]
good <- complete.cases(weight)
weight <- weight[good]
mpgc <- mpg - mean(mpg)
weightc <- weight - mean(weight)
beta <- sum(mpgc*weightc)/sum(weightc^2)
c(beta)
head(mtcars)
data(mtcars)
mpg <- mtcars$mpg
weight <- mtcars$wt
mpgc <- mpg - mean(mpg)
weightc <- weight - mean(weight)
beta <- sum(mpgc*weightc)/sum(weightc^2)
c(beta)
install.packages("RMySAL", type="source")
install.packages("RMySQL", type="source")
library(RMySQL)
R.home()
install.packages("RMySQL")
install.packages("RMySQL", type='source')
con = url("http://jpora452.rsjp.net/cgi-bin/search_h/search_e.cgi")
htmlCode = readLines(con)
close(con)
head(htmlCode)
htmlCode
library(XML)
url <- "http://jpora452.rsjp.net/cgi-bin/search_h/search_e.cgi"
html <- htmlTreeParse(url, useInternalNodes=T)
xpathsApply(html,"//title", xmlValue)
xpathSApply(html,"//title", xmlValue)
xpathSApply(html,"//name", xmlValue)
library(httr)
url <- "https://api.github.com/users/jtleek/repos"
html2 = GET(url)
names(html2)
content = content(html2, as="text")
names(content)
head(content)
parseHtml = htmlParse(content, asText=TRUE)
library(html)
library(httr)
library(XML)
parseHtml = htmlParse(content, asText=TRUE)
xpathSApply(parseHtml, "//datasharing", xmlValue)
xpathSApply(parseHtml, "created", xmlValue)
xpathSApply(parseHtml, "id", xmlValue)
xpathSApply(parseHtml, "//title", xmlValue)
class(content)
length(content)
library(httr)
oauth_endpoints("github")
myapp <- oauth_app("github")
myapp <- oauth_app("github", 6ba4c2c2b4d271ffabd9, 5ef1646c79496f3b306c7ee43562d32ef860a78d)
myapp <- oauth_app("github", key = "6ba4c2c2b4d271ffabd9", secret="5ef1646c79496f3b306c7ee43562d32ef860a78d")
github_token <- oauth2.0_token(oauth_endpoints("github"),myapp)
github_token
oauth_endpoints("github")
myapp <- oauth_app("github", key="6ba4c2c2b4d271ffabd9", secret="5ef1646c79496f3b306c7ee43562d32ef860a78d")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
sig =sign_oauth1.0(myapp, token = "datasharing", token_scret="089b2d3b09b4db6cc1a66b3623a398cdb1a4dfae")
gomeTL = GET("https://api.github.com/users/jtleek/repos", sig)
gomeTL
GET https://github.com/login/oauth/authorize
GET("https://github.com/login/oauth/authorize")
POST("https://github.com/login/oauth/authorize")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
library(sqldf)
install.packages("sqldf")
getwd()
library(sqldf)
list.files("./")
acs <- read.csv("gcq2q2.csv")
sqldf("select pwgtp1 from acs where AHEP < 50")
sqldf("select pwgtp1 from acs where AGEP < 50")
option1 <- sqldf("select pwgtp1 from acs where AGEP < 50")
head(option1)
option2 <- sqldf("select pwgtp1 from acs")
head(option2)
option3 <- sqldf("select * from acs where AGEP < 50")
head(option3)
option4 <- sqldf("select * from acs where AGEP < 50 and pwgtp1")
head(option4)
data <- with(acs, tapply(pwgtp1, AGEP<50))
head(data)
data <- with(acs, tapply(pwgtp1, AGEP))
head(data)
class(data)
data <- acs[acs[,"AGEP"]<50,]
data==option1
data=option1
data <- acs[acs[,"AGEP"]<50,]
head(data)
data <- data[,"pwgtp1"]
head(data)
head(option1)
head(option2)
tail(data)
tail(option1)
tail(option2)
option <- sqldf("select AGEP where unique from acs")
library(sqldf)
option <- sqldf("select AGEP where unique from acs")
option1 <- sqldf("select AGEP where unique from acs")
option2 <- sqldf("select distinct AGEP from acs")
option3 <- sqldf("select unique AGEP from acs")
option4 <- sqldf("select unique * from acs")
head(option2)
con <- url("http://biostat.jhsph.edu/~jleek/contact.html ")
htmlcode = readLines(con)
close(con)
class(htmlcode)
length(htmlcode)
nchar(htmlcode[10])
nchar(htmlcode[20])
nchar(htmlcode[30])
nchar(htmlcode[100])
con = url("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for ")
htmlCode = readLines(con)
class(htmlCode)
dim(htmlcode)
length(htmlCode)
dim(htmlCode)
head(htmlCode)
htmlCode[1]
htmlCode[2]
htmlCode[3]
htmlCode[4]
htmlCode[5]
data <- data.table(con)
?readLines
library(XML)
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for "
html <- htmlTreeParse(url, useInternalNodex=T)
?split
?separate
?separate()
?divide()
head(htmlCode)
strsplit(htmlCode, " ")
data <- strsplit(htmlCode, " ")
head(data)
head(htmlCode)
?read.fwf
data <- read.fwf(file=url, widths=5, skip=3)
head(data)
data <- read.fwf(file=url, widths=5, skip=4)
head(data)
data <- read.fwf(file=url, widths=c(12,7,4,9,4,9,4), skip=4)
head(data)
data <- read.fwf(file=url, widths=c(10,7,4,9,4,9,4), skip=4)
head(data)
data <- read.fwf(file=url, widths=c(12,7,4,9,4,9,4), skip=4)
head(data)
data <- read.fwf(file=url, widths=c(12,7,4,9,4,9,4,9), skip=4)
head(data)
data <- read.fwf(file=url, widths=c(12,7,4,9,4,9,4,9,4), skip=4)
head(data)
class(data)
dim(data)
sum(data[,8])
sum(data[,9])
35824.9+36.5
clear()
library(jsondata)
library(jsonlite)
json <- url(https://api.github.com/users/jtleek/repos)
json <- url("https://api.github.com/users/jtleek/repos")
json
json <- fromJSON("https://api.github.com/users/jtleek/repos")
names(json)
json$i
json$id
json$name
json$name$datasharing
class(json$name)
json2 = jsonlite::fromJSON(toJSON(json))
class(json2)
class(json)
names(json2)
json2$name$datasharing
json2[1,1:4]
json
head(json)
head(json2)
json[1,1:4]
json2 <- json[json[,2]=="datasharing"]
json2
json2 = jsonlite::fromJSON(toJSON(json))
jsondata <- json2[json2[,2]=="datasharing"]
jsondata
json[1,1:4]
jsondata <- json[json[,2]=="datasharin",]
jsondata
jsondata <- json[json[,2]=="datasharing",]
jsondata
head(jsondata)
jsondata[1,1:4]
jsondata[,"created"]
jsondata[,"created_at"]
url <- url("http://biostat.jhsph.edu/~jleek/contact.html ")
url <- url("http://biostat.jhsph.edu/~jleek/contact.html")
data <- readLines(url)
nchar(c(10,20,30,100))
nchar(data[c(10,20,30,100)])
web <- url("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for")
htmlcode <- readLines(web)
head(htmlcode)
table <- read.fwf(htmlcode, widths=c(12,12,12,12,12), skip=4)
table <- read.fwf(htmlcode, widths=c(12,8,4,8,4,8,4,8,4), skip=4)
table <- read.fwf(file=htmlcode, widths=c(12,12,12,12), skip=4)
table <- read.fwf(file=web, widths=c(12,12,12,12), skip=4)
table <- read.fwf(file=url("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"), widths=c(12,12,12,12), skip=4)
table <- read.fwf(file=url("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"), widths=c(12,8,4,8,4,8,4), skip=4)
head(table)
table <- read.fwf(file=url("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"), widths=c(12,9,4,9,4,9,4), skip=4)
head(table)
table <- read.fwf(file=url("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"), widths=c(12,7,4,9,4,9,4), skip=4)
head(table)
table <- read.fwf(file=url("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"), widths=c(12,7,4,9,4,9,4,9,4), skip=4)
head(table)
sum(data[,8],data[,9])
sum(data[,8])
sum(table[,8],table[,9])
class(table[,8])
class(table[,9])
sum(table[,8])
sum(table[,9])
sum(table[,6])
sum(table[,7])
33886.4-18.5
tail(table)
library(lattice)
q()
library(ggplot2)
library(dataset)
library(data.set)
library(datasets)
qplot(displ, hwy, data=mpg)
qplot(displ, hwy, data=mpg, color = drv)
qplot(displ, hwy, data=mpg, color = drv, geom=c("point", "smooth"))
qplot(displ, hwy, data=mpg, geom=c("point", "smooth"))
library(lattice)
xyplot(y~x | data=mpg)
xyplot(hwy~displ | data=mpg)
xyplot(hwy ~ displ | drv, data = mpg)
xyplot(hwy ~ displ | drv, data = mpg, layout = c(3,1))
qplot(displ, hwy, data = mpg, factes=.~drv)
qplot(displ, hwy, data = mpg, facets=.~drv)
library(lattice)
library(datasets)
?panel.lmline()
?axis()
?panel.lmline()
?lines()
?points()
?panel.lmline()
data(airquality)
p <- xyplot(Ozone ~ Wind|factor(Month), data=airquality)
p
?print.trellis()
print.trellis(p)
?splom
?par
?trellis.par.set
qplot(Wind,Ozone, data=airquality)
library(ggplot2)
qplot(Wind,Ozone, data=airquality)
qplot(Wind,Ozone, data=airquality, facets=. ~ factor(Month))
airquality = transform(airquality, Month=factor(Month))
qplot(Wind, Ozone, data= airquality, facets = .~Month)
head(airquality)
airquality2 = transform(airquality, Month=factor(Month))
head(airquality2)
qplot(Wind, Ozone, data= airquality, geom="smooth")
?geom
??geom
qplot(votes, rating, data=movies)
qplot(votes, rating, data=movies) + geom_smooth()
qplot(votes, rating, data=movies) + stats_smooth("loess")
qplot(votes, rating, data=movies, panel = panel.loess_
)
qplot(votes, rating, data=movies, panel = panel.loess)
qplot(votes, rating, data=movies, smooth = "loess")
library(knitr)
install.packages("knitr")
library(XML)
fiileUrl <- "http://jpora452.rsjp.net/cgi-bin/search_h/search_e.cgi"
doc <- xmlTreeParse(fileUrl, useInternal=TRUE)
rootNode <- xmlRoot(doc)
xmlName(rootNode)
library(XML)
fileUrl <- "http://jpora452.rsjp.net/cgi-bin/search_h/search_e.cgi"
doc <- xmlTreeParse(fileUrl, useInternal=TRUE)
rootNode <- xmlRoot(doc)
xmlName(rootNode)
fileUrl <- "http://jpora452.rsjp.net/cgi-bin/search_h/search_e.cgi"
doc <- xmlTreeParse(fileUrl, useInternal=TRUE)
rootNode <- xmlRoot(doc)
library(html)
install.packages("html")
doc <- htmlTreeParse(fileUrl, useInternal=TRUE)
doc
fileUrl <- "http://jpora452.rsjp.net/cgi-bin/search_h/search_e.cgi?action=list&proc=&word=&key="
doc <- htmlTreeParse(fileUrl, useInternal=TRUE)
doc
head(doc)
doc <- htmlTreeParse(fileUrl, useInternal=TRUE)
doc
rootNode <- htmlRoot(doc)
rootNode <- xmlRoot(doc)
xmlName(rootNode)
class(rootNode)
rootNode
class(doc)
fileUrl<-"http://espn.go.com/nfl/team/_/name/bal/baltimore-ravens"
doc <- htmlTreeParse(fileUrl, useInternal=TRUE)
scores <- xpathSApply(doc, "//li[@class='score']",xmlValue)
teams <- xpathSApply(doc, "//li[@class='team-name']",xmlValue)
scores
teams
library(XML)
fileUrl <- "view-source:http://jpora452.rsjp.net/cgi-bin/search_h/search_e.cgi?action=diss_main&effect=112%20&find=Alprazolam&mode="
doc <- xmlTreeParse(fileUrl, useInternal=TRUE)
rootNode <- xmlRoot(doc)
xmlName(rootNode)
doc <- htmlTreeParse(fileUrl, useInternal=TRUE)
fileUrl <- "http://jpora452.rsjp.net/cgi-bin/search_h/search_e.cgi?action=diss_main&effect=112%20&find=Alprazolam&mode="
doc <- htmlTreeParse(fileUrl, useInternal=TRUE)
rootNode <- htmlRoot(doc)
rootNode <- xmlRoot(doc)
names(rootNode)
rootNode[[1]]
rootNode[[1]][[1]]
xmlSApply(rootNode, xmlValue)
xpathSApply(rootNode, "//name", xmlValue)
?xmlValue
xpathSApply(rootNode, "//table", xmlValue)
fileUrl <- "http://jpora452.rsjp.net/cgi-bin/search_h/search_e.cgi?action=diss_imgview&img=07_01_Alprazolam_T1.gif"
doc <- htmlTreeParse(fileUrl, useInternal=TRUE)
rootNode <- xmlRoot(doc)
xmlName(rootNode)
rootNode[[1]]
rootNode[[2]]
rootNode[[2]][[1]]
rootNode[[2]][[1]]
rootNode[[2]][[2]]
download.files(rootNode[[2]][[2]])
download.file(rootNode[[2]][[2]],destfile="./data",method="curl")
getwd()
data <- read.csv("activity.csv")
##mean total number of steps taken per day
good <- complete.cases(data)
data2 <- data[good, ]
sum.step <- with(data2, tapply(data2$steps, data2$date, sum))
data.hist <- data.frame("date"=strptime(names(sum.step),"%Y-%m-%d"),
"steps"=sum.step, row.names=NULL)
with(data.hist, barplot(steps, names=date, xlab="date",
)
q()
list.files(",.")
list.files("./")
setwd(paste(getwd(),RepData_PeerAssessment1,sep="/"))
setwd(paste(getwd(),"RepData_PeerAssessment1",sep="/"))
getwd()
data <- read.csv("activity.csv")
##mean total number of steps taken per day
good <- complete.cases(data)
data2 <- data[good, ]
sum.step <- with(data2, tapply(data2$steps, data2$date, sum))
data.hist <- data.frame("date"=strptime(names(sum.step),"%Y-%m-%d"),
"steps"=sum.step, row.names=NULL)
with(data.hist, barplot(steps, names=date, xlab="date",
ylab="total number of steps taken each day", col="green"))
mean.day <- mean(sum.step, na.rm=TRUE)
mean.day
median.day <- median(sum.step, na.rm=TRUE)
median.day
##average daily activity pattern
#sorting function and get mean
sortANDgetmean <- function(data){
data.order <- order(data$interval)
data.sorted <- data[data.order, ]
mean <- with(data.sorted, tapply(data.sorted$steps, data.sorted$interval, mean))
mean
}
mean.step <- sortANDgetmean(data2)
plot(names(mean.step), mean.step, type="l",
xlab="5-minute interval", ylab="average number of steps")
##imputing missing value
NA.row <- is.na(data)
NA.row2 <- NA.row[NA.row[,1]==TRUE,]
length(NA.row2[,1])
data3 <- data
for(i in 1:length(data3[,1])) {
if(is.na(data3[i,1])){
flag <- as.character(data3[i,"interval"])
#fill missing value with mean for 5-minute value
data3[i,1] <- mean.step[flag]
}
}
sum.step2 <- with(data3, tapply(data3$steps, data3$date, sum))
data.hist2 <- data.frame("date"=strptime(names(sum.step2),"%Y-%m-%d"),
"steps"=sum.step2, row.names=NULL)
with(data.hist2, barplot(steps, names=date, xlab="data",
ylab="total number of steps taken each day", col="red"))
mean.day2 <- mean(sum.step2)
mean.day2
median.day2 <- median(sum.step2)
median.day2
##difference in activity patterns between weekdays and weekends
#What's wrong with week?? it was working few minutes ago
data.factor <- factor(c("weekday","weekend"))
week <- weekdays(data3$date, abb=TRUE)
head(data3)
class(data3$date)
class(data$date)
data3$date <- strptime(data3$date, "%Y-%m-%d")
week <- weekdays(data3$date, abb=TRUE)
for(i in 1:length(week)) {
if(week[i] == "토")
week[i] <- data.factor[2]
else if(week[i]== "일")
week[i] <- data.factor[2]
else
week[i] <- data.factor[1]
}
data4 <- data.frame(data3, "day"=week)
data.weekday <- data4[data4$day==1,]
data.weekend <- data4[data4$day==2,]
weekday.step <- sortANDgetmean(data.weekday)
weekend.step <- sortANDgetmean(data.weekend)
data4 <- data.frame("interval"=as.numeric(names(weekday.step)), "steps"=weekday.step,
"day"=data.factor[1], row.names=NULL)
data5 <- data.frame("interval"=as.numeric(names(weekend.step)), "steps"=weekend.step,
"day"=data.factor[2], row.names=NULL)
total.data <- rbind(data4, data5)
library(lattice)
xyplot(steps~interval | day, data=total.data, layout=c(1,2), type="l",
xlab="Interval", ylab="Number of steps")
?knit2html()
library(knitr)
?knit2html()
knit2html(PA1_template.Rmd)
knit2html("PA1_template.Rmd")
knit2html("PA1_template.md")
knit2html("PA1_template.txt")
ylab="total number of steps taken each day", col="green"))
with(data.hist, barplot(steps, names=date, xlab="date",
ylab="total number of steps taken each day", col="green"))
dev.copy(png, file="/figures/1.png")
library(knitr)
knitr2html("PA1_template.Rmd")
knit2html("PA1_template.Rmd")
